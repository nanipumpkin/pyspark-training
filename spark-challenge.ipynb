{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio: Consumo de Dados para Previsão do Tempo das Cidades do Vale do Paraíba.\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Avaliar conhecimentos nas linguagens Python e SQL e na engine de processamento Apache Spark.\n",
    "\n",
    "## Descrição\n",
    "\n",
    "Neste desafio, você desenvolverá um notebook que será responsável por extrair dados de previsão do tempo das cidades do Vale do Paraíba, região onde se localiza a Dataside. Para consultar todas as cidades dessa região, utilizaremos a API do IBGE. No caso, basta realizar uma requisição HTTP com o método GET, utilizando a URL abaixo:\n",
    "\n",
    "```\n",
    "https://servicodados.ibge.gov.br/api/v1/localidades/mesorregioes/3513/municipios\n",
    "```\n",
    "\n",
    "Com esses dados, gerar um data frame e a partir dele uma temp view. Ex: \"cities\"\n",
    "\n",
    "Utilizando os nomes das cidades, deverão ser consultados os dados de previsão de tempo para cada cidade. Para realizar essa consulta, poderá ser utilizada qualquer uma das APIs informadas no link abaixo.\n",
    "\n",
    "[Public APIs - Wather](https://github.com/public-apis/public-apis#weather)\n",
    "\n",
    "Obs.: Para algumas, pode ser necessário cadastrar-se para acessar sua API Key. Mas nenhuma delas deve precisar cadastrar cartão de crédito ou adicionar qualquer valor monetário para utilizar. Caso alguma solicite, basta optar por outra.\n",
    "\n",
    "Com os dados consultados, gerar um data frame e partir dele outra temp view. Ex: \"forecasts\"\n",
    "\n",
    "Com as temp views geradas, utilizar Spark SQL para criar queries e gerar data frames das seguintes tabelas:\n",
    "\n",
    "- Tabela 1: dados de previsão do tempo para os próximos cinco dias, para cada data e cidade consultadas. As colunas dessa tabela serão:\n",
    "    - Cidade\n",
    "    - CodigoDaCidade\n",
    "    - Data\n",
    "    - Regiao\n",
    "    - Pais\n",
    "    - Latitude\n",
    "    - Longigute\n",
    "    - TemperaturaMaxima\n",
    "    - TemperaturaMinima\n",
    "    - TemperaturaMedia\n",
    "    - VaiChover\n",
    "    - ChanceDeChuva\n",
    "    - CondicaoDoTempo\n",
    "    - NascerDoSol\n",
    "    - PorDoSol\n",
    "    - VelocidadeMaximaDoVento\n",
    "    \n",
    "    Obs.: Os valores da coluna \"VaiChover\" deverá ser \"Sim\" ou \"Não\". E a coluna \"CodigoDaCidade\" é o ID retornado junto com os nomes da cidades na API do IBGE.\n",
    "    Obs.: Dependendo da API utilizada, algumas colunas podem não existir e ficarão em branco. Você deve optar por uma API que traga o maior número de informações possível.\n",
    "\n",
    "- Tabela 2: quantidade de dias com chuva e sem chuva para os dias consultados, para cada data consultada. Colunas:\n",
    "    - Cidade\n",
    "    - QtdDiasVaiChover\n",
    "    - QtdDiasNaoVaiChover\n",
    "    - TotalDiasMapeados\n",
    "\n",
    "Essas tabelas deverão ser exportadas em formado CSV e entregue no final do desafio.\n",
    "\n",
    "## To Do\n",
    "\n",
    "[ ] - Consultar municípios do Vale do Paraíba, gerar um data frame e criar uma temp view com esses dados.\n",
    "[ ] - Consultar dados do tempo para cada município, gerar um data frame e criar uma outra temp view.\n",
    "[ ] - Utilizar Spark SQL para gerar os data frames das Tabelas 1 e 2.\n",
    "[ ] - Exportar os data frames para CSV.\n",
    "\n",
    "## Atenção\n",
    "\n",
    "- Existe um limite de requisições de 10000 requests por conta cadastrada na m3o.\n",
    "- Essa API pode retornar cidades de outras regiões que possuem nome semelhante a alguma cidade do Vale do Paraiba. Pode mantê-las ou filtrar para gerar as tabelas apenas com dados de Regiao = Sao Paulo. Fica a seu critério.\n",
    "\n",
    "## Entregando o desafio\n",
    "\n",
    "Concluindo todos os passos informados em To Do, basta salvar o arquivo .ipynb do notebook e enviar para a Dataside juntamente com os CSVs das duas tabelas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import urllib3\n",
    "import ssl\n",
    "import json\n",
    "import unidecode\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "      .master(\"local[1]\") \\\n",
    "      .appName(\"SparkByExamples.com\") \\\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomHttpAdapter (requests.adapters.HTTPAdapter):\n",
    "    # \"Transport adapter\" that allows us to use custom ssl_context.\n",
    "\n",
    "    def __init__(self, ssl_context=None, **kwargs):\n",
    "        self.ssl_context = ssl_context\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def init_poolmanager(self, connections, maxsize, block=False):\n",
    "        self.poolmanager = urllib3.poolmanager.PoolManager(\n",
    "            num_pools=connections, maxsize=maxsize,\n",
    "            block=block, ssl_context=self.ssl_context)\n",
    "\n",
    "\n",
    "def get_legacy_session():\n",
    "    ctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n",
    "    ctx.options |= 0x4  # OP_LEGACY_SERVER_CONNECT\n",
    "    session = requests.session()\n",
    "    session.mount('https://', CustomHttpAdapter(ctx))\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar cidades do Vale do Paraíba\n",
    "# TODO\n",
    "IBGE_API = 'https://servicodados.ibge.gov.br/api/v1/localidades/mesorregioes/3513/municipios'\n",
    "REQ_CITIES = get_legacy_session().get(IBGE_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar data frame com as cidades\n",
    "# TODO\n",
    "CITIES_REQ = REQ_CITIES.json()\n",
    "CITIES_FILE = \"./data/cities/cities.json\"\n",
    "os.makedirs(os.path.dirname(CITIES_FILE), exist_ok=True)\n",
    "with open(CITIES_FILE, 'w') as f:\n",
    "  json.dump(CITIES_REQ, f)\n",
    "\n",
    "cities = spark.read.json(CITIES_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+--------------------+\n",
      "|     id|        microrregiao|              nome|     regiao-imediata|\n",
      "+-------+--------------------+------------------+--------------------+\n",
      "|3502507|{35051, {{35, São...|         Aparecida|{350052, Guaratin...|\n",
      "|3503158|{35052, {{35, São...|            Arapeí|{350053, Cruzeiro...|\n",
      "|3503505|{35052, {{35, São...|            Areias|{350053, Cruzeiro...|\n",
      "|3504909|{35052, {{35, São...|           Bananal|{350053, Cruzeiro...|\n",
      "|3508504|{35050, {{35, São...|          Caçapava|{350049, São José...|\n",
      "|3508603|{35051, {{35, São...|Cachoeira Paulista|{350053, Cruzeiro...|\n",
      "|3509700|{35049, {{35, São...|  Campos do Jordão|{350050, Taubaté ...|\n",
      "|3509957|{35051, {{35, São...|             Canas|{350052, Guaratin...|\n",
      "|3510500|{35054, {{35, São...|     Caraguatatuba|{350051, Caraguat...|\n",
      "|3513405|{35051, {{35, São...|          Cruzeiro|{350053, Cruzeiro...|\n",
      "|3513603|{35053, {{35, São...|             Cunha|{350052, Guaratin...|\n",
      "|3518404|{35051, {{35, São...|     Guaratinguetá|{350052, Guaratin...|\n",
      "|3520202|{35050, {{35, São...|           Igaratá|{350049, São José...|\n",
      "|3520400|{35054, {{35, São...|          Ilhabela|{350051, Caraguat...|\n",
      "|3524402|{35050, {{35, São...|           Jacareí|{350049, São José...|\n",
      "|3524907|{35053, {{35, São...|          Jambeiro|{350049, São José...|\n",
      "|3526308|{35053, {{35, São...|          Lagoinha|{350050, Taubaté ...|\n",
      "|3526605|{35051, {{35, São...|         Lavrinhas|{350053, Cruzeiro...|\n",
      "|3527207|{35051, {{35, São...|            Lorena|{350052, Guaratin...|\n",
      "|3531704|{35049, {{35, São...|   Monteiro Lobato|{350049, São José...|\n",
      "+-------+--------------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criar view com as cidades\n",
    "# TODO\n",
    "cities.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "|              nome|     id|\n",
      "+------------------+-------+\n",
      "|         Aparecida|3502507|\n",
      "|            Arapeí|3503158|\n",
      "|            Areias|3503505|\n",
      "|           Bananal|3504909|\n",
      "|          Caçapava|3508504|\n",
      "|Cachoeira Paulista|3508603|\n",
      "|  Campos do Jordão|3509700|\n",
      "|             Canas|3509957|\n",
      "|     Caraguatatuba|3510500|\n",
      "|          Cruzeiro|3513405|\n",
      "|             Cunha|3513603|\n",
      "|     Guaratinguetá|3518404|\n",
      "|           Igaratá|3520202|\n",
      "|          Ilhabela|3520400|\n",
      "|           Jacareí|3524402|\n",
      "|          Jambeiro|3524907|\n",
      "|          Lagoinha|3526308|\n",
      "|         Lavrinhas|3526605|\n",
      "|            Lorena|3527207|\n",
      "|   Monteiro Lobato|3531704|\n",
      "+------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecionar colunas relevantes\n",
    "cities_filtered = cities.select(['nome', 'id'])\n",
    "cities_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+\n",
      "|            Cidade|CodigoDaCidade|\n",
      "+------------------+--------------+\n",
      "|         Aparecida|       3502507|\n",
      "|            Arapeí|       3503158|\n",
      "|            Areias|       3503505|\n",
      "|           Bananal|       3504909|\n",
      "|          Caçapava|       3508504|\n",
      "|Cachoeira Paulista|       3508603|\n",
      "|  Campos do Jordão|       3509700|\n",
      "|             Canas|       3509957|\n",
      "|     Caraguatatuba|       3510500|\n",
      "|          Cruzeiro|       3513405|\n",
      "|             Cunha|       3513603|\n",
      "|     Guaratinguetá|       3518404|\n",
      "|           Igaratá|       3520202|\n",
      "|          Ilhabela|       3520400|\n",
      "|           Jacareí|       3524402|\n",
      "|          Jambeiro|       3524907|\n",
      "|          Lagoinha|       3526308|\n",
      "|         Lavrinhas|       3526605|\n",
      "|            Lorena|       3527207|\n",
      "|   Monteiro Lobato|       3531704|\n",
      "+------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renomear colunas\n",
    "cities_renamed = cities_filtered.withColumnRenamed('nome', 'Cidade') \\\n",
    "                                .withColumnRenamed('id', 'CodigoDaCidade')\n",
    "cities_renamed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Cidade: string (nullable = true)\n",
      " |-- CodigoDaCidade: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cities_renamed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aparecida', 'Arapeí', 'Areias', 'Bananal', 'Caçapava', 'Cachoeira Paulista', 'Campos do Jordão', 'Canas', 'Caraguatatuba', 'Cruzeiro', 'Cunha', 'Guaratinguetá', 'Igaratá', 'Ilhabela', 'Jacareí', 'Jambeiro', 'Lagoinha', 'Lavrinhas', 'Lorena', 'Monteiro Lobato', 'Natividade da Serra', 'Paraibuna', 'Pindamonhangaba', 'Piquete', 'Potim', 'Queluz', 'Redenção da Serra', 'Roseira', 'Santa Branca', 'Santo Antônio do Pinhal', 'São Bento do Sapucaí', 'São José do Barreiro', 'São José dos Campos', 'São Luiz do Paraitinga', 'São Sebastião', 'Silveiras', 'Taubaté', 'Tremembé', 'Ubatuba']\n"
     ]
    }
   ],
   "source": [
    "cities_list = cities_renamed.rdd.map(lambda x: x.Cidade).collect()\n",
    "print(cities_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar previsão do tempo para as cidades\n",
    "# TODO\n",
    "\n",
    "M3O_API_KEY = \"ZTc0NTIzMTAtYjY2Ni00MDJkLWI3MjUtOTZlZjUzMzhiZGMx\"\n",
    "M3O_API_WEATHER_FORECAST = \"https://api.m3o.com/v1/weather/Forecast\"\n",
    "\n",
    "WEATHER_PATH = \"./data/weather/\"\n",
    "os.makedirs(os.path.dirname(WEATHER_PATH), exist_ok=True)\n",
    "\n",
    "cities_list = cities.rdd.map(lambda x: x.nome).collect()\n",
    "days = 5\n",
    "\n",
    "for city in cities_list:\n",
    "  PARAMS = {\"days\":days,\"location\":city}\n",
    "  headers = {\n",
    "      'Content-Type': \"application/json\",\n",
    "      'Authorization': \"Bearer \" + M3O_API_KEY\n",
    "  }\n",
    "  REQ_WEATHER = requests.get(M3O_API_WEATHER_FORECAST, headers=headers, params=PARAMS)\n",
    "\n",
    "  WEATHER = REQ_WEATHER.json()\n",
    "\n",
    "  with open(f'{WEATHER_PATH}{city}.json', 'w') as f:\n",
    "    json.dump(WEATHER, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+--------------------+----+--------+----------------+--------------------+---------+----------+------+------------------+\n",
      "|code|   country|detail|            forecast|  id|latitude|      local_time|            location|longitude|    region|status|          timezone|\n",
      "+----+----------+------+--------------------+----+--------+----------------+--------------------+---------+----------+------+------------------+\n",
      "|null|    Brazil|  null|[{20.2, 68.4, 86,...|null|  -22.83|2023-01-11 17:20|           Aparecida|   -45.23| Sao Paulo|  null| America/Sao_Paulo|\n",
      "|null|    Brazil|  null|[{23.8, 74.9, 79,...|null|  -12.63|2023-01-11 17:21|  Caldeirao Do Bento|   -40.27|     Bahia|  null|     America/Bahia|\n",
      "|null|    Brazil|  null|[{28.0, 82.3, 82,...|null|   -7.97|2023-01-11 17:21|     Saco Dos Campos|   -38.08|Pernambuco|  null|    America/Recife|\n",
      "|null|    Brazil|  null|[{26.8, 80.3, 85,...|null|  -10.32|2023-01-11 17:21|            Lagoinha|    -38.9|     Bahia|  null|     America/Bahia|\n",
      "|null|    Brazil|  null|[{27.7, 81.9, 89,...|null|   -6.45|2023-01-11 17:20|              Areias|   -38.43|   Paraiba|  null| America/Fortaleza|\n",
      "|null|    Brazil|  null|[{25.3, 77.5, 85,...|null|   -7.63|2023-01-11 15:21|     Cruzeiro Do Sul|    -72.6|      Acre|  null|America/Rio_Branco|\n",
      "|null|Costa Rica|  null|[{24.5, 76.0, 85,...|null|   10.43|2023-01-11 14:21|               Canas|    -85.1|Guanacaste|  null|America/Costa_Rica|\n",
      "|null|    Brasil|  null|[{24.1, 75.3, 88,...|null|   -23.8|2023-01-11 17:21|       São Sebastião|   -45.42| Sao Paulo|  null| America/Sao_Paulo|\n",
      "|null|    Brazil|  null|[{25.8, 78.5, 89,...|null|  -11.88|2023-01-11 17:21|Barreiro Do Nasci...|   -50.63| Tocantins|  null| America/Araguaina|\n",
      "|null|    Brazil|  null|[{20.8, 69.4, 92,...|null|  -22.67|2023-01-11 17:20|  Cachoeira Paulista|   -45.02| Sao Paulo|  null| America/Sao_Paulo|\n",
      "|null|  Portugal|  null|[{12.5, 54.5, 96,...|null|   38.53|2023-01-11 20:21|Monte Da Serra Da...|    -8.38|     Evora|  null|     Europe/Lisbon|\n",
      "|null|    Brazil|  null|[{20.7, 69.2, 92,...|null|  -22.83|2023-01-11 17:21|Santo Antonio Do ...|   -45.67| Sao Paulo|  null| America/Sao_Paulo|\n",
      "|null|    Brazil|  null|[{21.0, 69.7, 89,...|null|  -22.97|2023-01-11 17:21|     Monteiro Lobato|   -45.83| Sao Paulo|  null| America/Sao_Paulo|\n",
      "|null|    Brazil|  null|[{24.1, 75.3, 88,...|null|  -23.62|2023-01-11 17:21|       Caraguatatuba|   -45.42| Sao Paulo|  null| America/Sao_Paulo|\n",
      "|null|    Brazil|  null|[{22.4, 72.3, 87,...|null|   -23.4|2023-01-11 17:21| Natividade Da Serra|   -45.43| Sao Paulo|  null| America/Sao_Paulo|\n",
      "|null|    Brazil|  null|[{21.3, 70.4, 89,...|null|  -23.23|2023-01-11 17:21|Sao Luiz Do Parai...|   -45.33| Sao Paulo|  null| America/Sao_Paulo|\n",
      "|null|    Brasil|  null|[{21.0, 69.7, 89,...|null|   -23.1|2023-01-11 17:20|            Caçapava|   -45.72| Sao Paulo|  null| America/Sao_Paulo|\n",
      "|null|    Brazil|  null|[{20.2, 68.4, 86,...|null|  -22.92|2023-01-11 17:21|     Pindamonhangaba|   -45.47| Sao Paulo|  null| America/Sao_Paulo|\n",
      "|null|    Brésil|  null|[{21.3, 70.4, 89,...|null|  -23.03|2023-01-11 17:21|             Taubaté|   -45.55| Sao Paulo|  null| America/Sao_Paulo|\n",
      "|null|    Brazil|  null|[{20.8, 69.4, 92,...|null|  -22.73|2023-01-11 17:21|              Lorena|   -45.13| Sao Paulo|  null| America/Sao_Paulo|\n",
      "+----+----------+------+--------------------+----+--------+----------------+--------------------+---------+----------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criar data frame com as previsões\n",
    "# TODO\n",
    "weather = spark.read.option(\"multiline\", \"true\").json(\"./data/weather/*.json\")\n",
    "\n",
    "# Criar view com as previsões\n",
    "# TODO\n",
    "weather.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+----------+----------+--------+---------+--------------------+\n",
      "|            location|      local_time|    region|   country|latitude|longitude|            forecast|\n",
      "+--------------------+----------------+----------+----------+--------+---------+--------------------+\n",
      "|           Aparecida|2023-01-11 17:20| Sao Paulo|    Brazil|  -22.83|   -45.23|[{20.2, 68.4, 86,...|\n",
      "|  Caldeirao Do Bento|2023-01-11 17:21|     Bahia|    Brazil|  -12.63|   -40.27|[{23.8, 74.9, 79,...|\n",
      "|     Saco Dos Campos|2023-01-11 17:21|Pernambuco|    Brazil|   -7.97|   -38.08|[{28.0, 82.3, 82,...|\n",
      "|            Lagoinha|2023-01-11 17:21|     Bahia|    Brazil|  -10.32|    -38.9|[{26.8, 80.3, 85,...|\n",
      "|              Areias|2023-01-11 17:20|   Paraiba|    Brazil|   -6.45|   -38.43|[{27.7, 81.9, 89,...|\n",
      "|     Cruzeiro Do Sul|2023-01-11 15:21|      Acre|    Brazil|   -7.63|    -72.6|[{25.3, 77.5, 85,...|\n",
      "|               Canas|2023-01-11 14:21|Guanacaste|Costa Rica|   10.43|    -85.1|[{24.5, 76.0, 85,...|\n",
      "|       São Sebastião|2023-01-11 17:21| Sao Paulo|    Brasil|   -23.8|   -45.42|[{24.1, 75.3, 88,...|\n",
      "|Barreiro Do Nasci...|2023-01-11 17:21| Tocantins|    Brazil|  -11.88|   -50.63|[{25.8, 78.5, 89,...|\n",
      "|  Cachoeira Paulista|2023-01-11 17:20| Sao Paulo|    Brazil|  -22.67|   -45.02|[{20.8, 69.4, 92,...|\n",
      "|Monte Da Serra Da...|2023-01-11 20:21|     Evora|  Portugal|   38.53|    -8.38|[{12.5, 54.5, 96,...|\n",
      "|Santo Antonio Do ...|2023-01-11 17:21| Sao Paulo|    Brazil|  -22.83|   -45.67|[{20.7, 69.2, 92,...|\n",
      "|     Monteiro Lobato|2023-01-11 17:21| Sao Paulo|    Brazil|  -22.97|   -45.83|[{21.0, 69.7, 89,...|\n",
      "|       Caraguatatuba|2023-01-11 17:21| Sao Paulo|    Brazil|  -23.62|   -45.42|[{24.1, 75.3, 88,...|\n",
      "| Natividade Da Serra|2023-01-11 17:21| Sao Paulo|    Brazil|   -23.4|   -45.43|[{22.4, 72.3, 87,...|\n",
      "|Sao Luiz Do Parai...|2023-01-11 17:21| Sao Paulo|    Brazil|  -23.23|   -45.33|[{21.3, 70.4, 89,...|\n",
      "|            Caçapava|2023-01-11 17:20| Sao Paulo|    Brasil|   -23.1|   -45.72|[{21.0, 69.7, 89,...|\n",
      "|     Pindamonhangaba|2023-01-11 17:21| Sao Paulo|    Brazil|  -22.92|   -45.47|[{20.2, 68.4, 86,...|\n",
      "|             Taubaté|2023-01-11 17:21| Sao Paulo|    Brésil|  -23.03|   -45.55|[{21.3, 70.4, 89,...|\n",
      "|              Lorena|2023-01-11 17:21| Sao Paulo|    Brazil|  -22.73|   -45.13|[{20.8, 69.4, 92,...|\n",
      "+--------------------+----------------+----------+----------+--------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_filtered = weather.select([\"location\",\"local_time\", \"region\", \"country\", \"latitude\", \"longitude\", \"forecast\"])\n",
    "weather_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+----------+----------+--------+---------+--------------------+\n",
      "|              Cidade|            Data|    Regiao|      Pais|Latitude|Longitude|            Previsao|\n",
      "+--------------------+----------------+----------+----------+--------+---------+--------------------+\n",
      "|           Aparecida|2023-01-11 17:20| Sao Paulo|    Brazil|  -22.83|   -45.23|[{20.2, 68.4, 86,...|\n",
      "|  Caldeirao Do Bento|2023-01-11 17:21|     Bahia|    Brazil|  -12.63|   -40.27|[{23.8, 74.9, 79,...|\n",
      "|     Saco Dos Campos|2023-01-11 17:21|Pernambuco|    Brazil|   -7.97|   -38.08|[{28.0, 82.3, 82,...|\n",
      "|            Lagoinha|2023-01-11 17:21|     Bahia|    Brazil|  -10.32|    -38.9|[{26.8, 80.3, 85,...|\n",
      "|              Areias|2023-01-11 17:20|   Paraiba|    Brazil|   -6.45|   -38.43|[{27.7, 81.9, 89,...|\n",
      "|     Cruzeiro Do Sul|2023-01-11 15:21|      Acre|    Brazil|   -7.63|    -72.6|[{25.3, 77.5, 85,...|\n",
      "|               Canas|2023-01-11 14:21|Guanacaste|Costa Rica|   10.43|    -85.1|[{24.5, 76.0, 85,...|\n",
      "|       São Sebastião|2023-01-11 17:21| Sao Paulo|    Brasil|   -23.8|   -45.42|[{24.1, 75.3, 88,...|\n",
      "|Barreiro Do Nasci...|2023-01-11 17:21| Tocantins|    Brazil|  -11.88|   -50.63|[{25.8, 78.5, 89,...|\n",
      "|  Cachoeira Paulista|2023-01-11 17:20| Sao Paulo|    Brazil|  -22.67|   -45.02|[{20.8, 69.4, 92,...|\n",
      "|Monte Da Serra Da...|2023-01-11 20:21|     Evora|  Portugal|   38.53|    -8.38|[{12.5, 54.5, 96,...|\n",
      "|Santo Antonio Do ...|2023-01-11 17:21| Sao Paulo|    Brazil|  -22.83|   -45.67|[{20.7, 69.2, 92,...|\n",
      "|     Monteiro Lobato|2023-01-11 17:21| Sao Paulo|    Brazil|  -22.97|   -45.83|[{21.0, 69.7, 89,...|\n",
      "|       Caraguatatuba|2023-01-11 17:21| Sao Paulo|    Brazil|  -23.62|   -45.42|[{24.1, 75.3, 88,...|\n",
      "| Natividade Da Serra|2023-01-11 17:21| Sao Paulo|    Brazil|   -23.4|   -45.43|[{22.4, 72.3, 87,...|\n",
      "|Sao Luiz Do Parai...|2023-01-11 17:21| Sao Paulo|    Brazil|  -23.23|   -45.33|[{21.3, 70.4, 89,...|\n",
      "|            Caçapava|2023-01-11 17:20| Sao Paulo|    Brasil|   -23.1|   -45.72|[{21.0, 69.7, 89,...|\n",
      "|     Pindamonhangaba|2023-01-11 17:21| Sao Paulo|    Brazil|  -22.92|   -45.47|[{20.2, 68.4, 86,...|\n",
      "|             Taubaté|2023-01-11 17:21| Sao Paulo|    Brésil|  -23.03|   -45.55|[{21.3, 70.4, 89,...|\n",
      "|              Lorena|2023-01-11 17:21| Sao Paulo|    Brazil|  -22.73|   -45.13|[{20.8, 69.4, 92,...|\n",
      "+--------------------+----------------+----------+----------+--------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renomear colunas\n",
    "weather_renamed = weather_filtered.withColumnRenamed('location', 'Cidade') \\\n",
    "                                .withColumnRenamed('local_time', 'Data') \\\n",
    "                                .withColumnRenamed('region', 'Regiao') \\\n",
    "                                .withColumnRenamed('country', 'Pais') \\\n",
    "                                .withColumnRenamed('latitude', 'Latitude') \\\n",
    "                                .withColumnRenamed('longitude', 'Longitude') \\\n",
    "                                .withColumnRenamed('forecast', 'Previsao')\n",
    "weather_renamed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Cidade: string (nullable = true)\n",
      " |-- Data: string (nullable = true)\n",
      " |-- Regiao: string (nullable = true)\n",
      " |-- Pais: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Previsao: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- avg_temp_c: double (nullable = true)\n",
      " |    |    |-- avg_temp_f: double (nullable = true)\n",
      " |    |    |-- chance_of_rain: long (nullable = true)\n",
      " |    |    |-- condition: string (nullable = true)\n",
      " |    |    |-- date: string (nullable = true)\n",
      " |    |    |-- icon_url: string (nullable = true)\n",
      " |    |    |-- max_temp_c: double (nullable = true)\n",
      " |    |    |-- max_temp_f: double (nullable = true)\n",
      " |    |    |-- max_wind_kph: double (nullable = true)\n",
      " |    |    |-- max_wind_mph: double (nullable = true)\n",
      " |    |    |-- min_temp_c: double (nullable = true)\n",
      " |    |    |-- min_temp_f: double (nullable = true)\n",
      " |    |    |-- sunrise: string (nullable = true)\n",
      " |    |    |-- sunset: string (nullable = true)\n",
      " |    |    |-- will_it_rain: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather_renamed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data is already a DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 23\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Criar DF da Tabela 1\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# TODO\u001b[39;00m\n\u001b[1;32m      3\u001b[0m schema1 \u001b[39m=\u001b[39m StructType([\n\u001b[1;32m      4\u001b[0m       StructField(\u001b[39m\"\u001b[39m\u001b[39mCidade\u001b[39m\u001b[39m\"\u001b[39m, StringType(), \u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m      5\u001b[0m       StructField(\u001b[39m\"\u001b[39m\u001b[39mCodigodaCidade\u001b[39m\u001b[39m\"\u001b[39m, IntegerType(), \u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m       StructField(\u001b[39m\"\u001b[39m\u001b[39mVelocidadeMaximaDoVento\u001b[39m\u001b[39m\"\u001b[39m, StringType(), \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m ])\n\u001b[0;32m---> 23\u001b[0m table1 \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39;49mcreateDataFrame(data\u001b[39m=\u001b[39;49mweather, schema \u001b[39m=\u001b[39;49m schema1)\n\u001b[1;32m     24\u001b[0m table1\u001b[39m.\u001b[39mprintSchema()\n\u001b[1;32m     25\u001b[0m table1\u001b[39m.\u001b[39mshow(truncate\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/code/pyspark-training/venv/lib/python3.10/site-packages/pyspark/sql/session.py:875\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jvm\u001b[39m.\u001b[39mSparkSession\u001b[39m.\u001b[39msetActiveSession(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jsparkSession)\n\u001b[1;32m    874\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, DataFrame):\n\u001b[0;32m--> 875\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdata is already a DataFrame\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    877\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(schema, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    878\u001b[0m     schema \u001b[39m=\u001b[39m cast(Union[AtomicType, StructType, \u001b[39mstr\u001b[39m], _parse_datatype_string(schema))\n",
      "\u001b[0;31mTypeError\u001b[0m: data is already a DataFrame"
     ]
    }
   ],
   "source": [
    "# Criar DF da Tabela 1\n",
    "# TODO\n",
    "schema1 = StructType([\n",
    "      StructField(\"Cidade\", StringType(), True),\n",
    "      StructField(\"CodigodaCidade\", IntegerType(), True),\n",
    "      StructField(\"Data\", IntegerType(), True),\n",
    "      StructField(\"Regiao\", StringType(), True),\n",
    "      StructField(\"Pais\", StringType(), True),\n",
    "      StructField(\"Latitude\", DoubleType(), True),\n",
    "      StructField(\"Longitude\", DoubleType(), True),\n",
    "      StructField(\"TemperaturaMaxima\", DoubleType(), True),\n",
    "      StructField(\"TemperaturaMinima\", DoubleType(), True),\n",
    "      StructField(\"VaiChover\", BooleanType(), True),\n",
    "      StructField(\"ChanceDeChuva\", DoubleType(), True),\n",
    "      StructField(\"CondicaoDoTempo\", DoubleType(), True),\n",
    "      StructField(\"NascerDoSol\", StringType(), True),\n",
    "      StructField(\"PorDoSol\", StringType(), True),\n",
    "      StructField(\"VelocidadeMaximaDoVento\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "table1 = spark.createDataFrame(data = weather, schema = schema1)\n",
    "table1.printSchema()\n",
    "table1.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cidade\n",
    "    - QtdDiasVaiChover\n",
    "    - QtdDiasNaoVaiChover\n",
    "    - TotalDiasMapeados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DF da Tabela 2\n",
    "# TODO\n",
    "schema2 = StructType([\n",
    "    StructField(\"Cidade\", StringType(), True),\n",
    "    StructField(\"QtdDiasVaiChover\", IntegerType(), True),\n",
    "    StructField(\"QtdDiasNaoVaiChover\", IntegerType(), True),\n",
    "    StructField(\"TotalDiasMapeados\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "CSV data source does not support array<struct<avg_temp_c:double,avg_temp_f:double,chance_of_rain:bigint,condition:string,date:string,icon_url:string,max_temp_c:double,max_temp_f:double,max_wind_kph:double,max_wind_mph:double,min_temp_c:double,min_temp_f:double,sunrise:string,sunset:string,will_it_rain:boolean>> data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Exportar CSVs\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# TODO\u001b[39;00m\n\u001b[1;32m      3\u001b[0m cities_renamed\u001b[39m.\u001b[39mwrite\u001b[39m.\u001b[39moption(\u001b[39m\"\u001b[39m\u001b[39mheader\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m) \\\n\u001b[1;32m      4\u001b[0m     \u001b[39m.\u001b[39mcsv(\u001b[39m\"\u001b[39m\u001b[39m./data/csv/cities\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m weather_renamed\u001b[39m.\u001b[39;49mwrite\u001b[39m.\u001b[39;49moption(\u001b[39m\"\u001b[39;49m\u001b[39mheader\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m) \\\n\u001b[0;32m----> 7\u001b[0m     \u001b[39m.\u001b[39;49mcsv(\u001b[39m\"\u001b[39;49m\u001b[39m./data/csv/weather\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/code/pyspark-training/venv/lib/python3.10/site-packages/pyspark/sql/readwriter.py:1240\u001b[0m, in \u001b[0;36mDataFrameWriter.csv\u001b[0;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode(mode)\n\u001b[1;32m   1222\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_opts(\n\u001b[1;32m   1223\u001b[0m     compression\u001b[39m=\u001b[39mcompression,\n\u001b[1;32m   1224\u001b[0m     sep\u001b[39m=\u001b[39msep,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m     lineSep\u001b[39m=\u001b[39mlineSep,\n\u001b[1;32m   1239\u001b[0m )\n\u001b[0;32m-> 1240\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jwrite\u001b[39m.\u001b[39;49mcsv(path)\n",
      "File \u001b[0;32m~/code/pyspark-training/venv/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/code/pyspark-training/venv/lib/python3.10/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: CSV data source does not support array<struct<avg_temp_c:double,avg_temp_f:double,chance_of_rain:bigint,condition:string,date:string,icon_url:string,max_temp_c:double,max_temp_f:double,max_wind_kph:double,max_wind_mph:double,min_temp_c:double,min_temp_f:double,sunrise:string,sunset:string,will_it_rain:boolean>> data type."
     ]
    }
   ],
   "source": [
    "# Exportar CSVs\n",
    "# TODO\n",
    "cities_renamed.write.option(\"header\", True) \\\n",
    "    .csv(\"./data/csv/cities\")\n",
    "\n",
    "weather_renamed.write.option(\"header\", True) \\\n",
    "    .csv(\"./data/csv/weather\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "812c00da900191ab32ae0f9f7cd7cf4dd5bc6c7fc238a0d3266ec2172fe51654"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
